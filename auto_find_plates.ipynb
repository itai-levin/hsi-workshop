{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import matplotlib\n",
    "from spectral import *\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['font.size'] = 3\n",
    "matplotlib.rcParams['lines.linewidth'] = 0.5\n",
    "matplotlib.rcParams['axes.linewidth']= 0.5\n",
    "matplotlib.rcParams['xtick.major.width'] = 0.5\n",
    "from utils import *\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set the font family to Arial\n",
    "plt.rc('font', family='Arial')\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "plt.rcParams['font.size'] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = date.today()\n",
    "date_str = today.strftime('%d%b%Y')\n",
    "print ('Date prefix:', date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEDIR = 'cv2_analysis'\n",
    "if not os.path.isdir(SAVEDIR):\n",
    "    os.mkdir(SAVEDIR)\n",
    "    print ('Made', SAVEDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_with_unmixing (img, endmembers, reference_spectrum):\n",
    "    img_flattened= np.reshape(img, (img.shape[0]*img.shape[1], img.shape[2]))\n",
    "    img_flattened = img_flattened / np.nanmax(img_flattened, axis=1, keepdims=True)\n",
    "#     img_flattened[img_flattened==0] = np.nan\n",
    "    \n",
    "    mat = np.vstack([-reference_spectrum, endmembers])\n",
    "\n",
    "    #fit\n",
    "    scored_img = UCLS(img_flattened, mat)\n",
    "    scored_img[scored_img<0] = 0\n",
    "    scored_img  = np.reshape(scored_img[:,0], img.shape[:2])\n",
    "    return scored_img\n",
    "\n",
    "\n",
    "\n",
    "def sort_grid_list(points, tolerance=20):\n",
    "    import numpy as np\n",
    "    \n",
    "    points = np.array(points)\n",
    "    points_sorted_by_y = points[np.argsort(points[:, 1])]  # sort by y\n",
    "    \n",
    "    rows = []\n",
    "    current_row = [points_sorted_by_y[0]]\n",
    "    \n",
    "    for pt in points_sorted_by_y[1:]:\n",
    "        if abs(pt[1] - current_row[-1][1]) < tolerance:\n",
    "            current_row.append(pt)\n",
    "        else:\n",
    "            rows.append(current_row)\n",
    "            current_row = [pt]\n",
    "    rows.append(current_row)\n",
    "\n",
    "    # Sort each row by x (left to right)\n",
    "    sorted_points = [pt for row in rows for pt in sorted(row, key=lambda x: int(x[0]))]\n",
    "    return sorted_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = envi.open('data/input/087_ELOP Eden Fleshler/results/REFLECTANCE_087.hdr')\n",
    "hsi_img = np.array(lib.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference_file = np.load('../absorbance_data/bpHO-smURFP_infered_absorbance_from_pellets_30May2024.npy')\n",
    "# reference_file = np.load('../hsi_detect/absorbance_data/YF10_infered_absorbance_from_MAFATJul2023_low_flight.npy')\n",
    "\n",
    "reference_file = np.load('data/input/YF10_infered_absorbance_from_pellets_09Jul2024.npy')\n",
    "\n",
    "reference_wls = reference_file[0,:]\n",
    "reference_spec = reference_file[1,:] #*.1\n",
    "\n",
    "reference_spec = np.interp(lib.bands.centers, reference_wls, reference_spec)\n",
    "plt.plot(lib.bands.centers, reference_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_endmembers, clust_ls = kmeans_hierarchical_extract_endmembers(hsi_img, \n",
    "                                                         return_cluster_idxs=True, \n",
    "                                                         reference_spec=reference_spec, reduced_dims=3,\n",
    "                                                         filter_threshold=0.9)\n",
    "\n",
    "# cluster_based_extract_endmembers(hsi_img,10)\n",
    "# filt_endmembers = filter_endmembers(endmembers_gradient_A_B, reference_spec)\n",
    "\n",
    "scored_gradient = classify_with_unmixing(hsi_img, filt_endmembers[0], reference_spec)\n",
    "scored_gradient[scored_gradient<0] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(scored_gradient, vmax=0.8, cmap='inferno')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.box(False)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(1-hsi_img[:,:,np.argmax(reference_spec)],  cmap='inferno', vmin=0, vmax=1)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.box(False)\n",
    "plt.colorbar()\n",
    "print (lib.bands.centers[np.argmax(reference_spec)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "rgb_img = bandpass_rgb_function(hsi_img, lib.bands.centers, coeffs=[2.5,2.5,2.5])\n",
    "plt.imshow(rgb_img)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.box(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(hsi_img[:,:,np.argmax(reference_spec)]/np.trapz(hsi_img, axis=2),  cmap='inferno')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.box(False)\n",
    "plt.colorbar()\n",
    "print (lib.bands.centers[np.argmax(reference_spec)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_ellipse(array, center, radius_x, radius_y):\n",
    "    \"\"\"\n",
    "    Masks out an ellipse within a NumPy array.\n",
    "    \n",
    "    Parameters:\n",
    "        array (numpy.ndarray): The input array.\n",
    "        center (tuple): The center coordinates of the ellipse (row, column).\n",
    "        radius_x (int): The radius of the ellipse along the x-axis.\n",
    "        radius_y (int): The radius of the ellipse along the y-axis.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: The masked array with the ellipse.\n",
    "    \"\"\"\n",
    "    mask = np.zeros_like(array, dtype=bool)\n",
    "    rows, cols = array.shape[:2]\n",
    "    cx, cy = center\n",
    "    \n",
    "    y, x = np.ogrid[:rows, :cols]\n",
    "    mask[((x - cx) / radius_x) ** 2 + ((y - cy) / radius_y) ** 2 <= 1] = True\n",
    "    \n",
    "    masked_array = array*mask\n",
    "    return masked_array\n",
    "\n",
    "def make_ellipse_masks(mask_shape, centers, radii):\n",
    "    \"\"\"\n",
    "    Creates a mask for an ellipse of a given radius and center.\n",
    "    radii is a list of tuples defining the x and y dimensions of the ellipse.\n",
    "    \"\"\"\n",
    "    mask = np.zeros(mask_shape[:2])\n",
    "    for c, r in zip(centers, radii):\n",
    "        mask += mask_ellipse(np.ones_like(mask), c, r[0], r[1])\n",
    "    return mask\n",
    "\n",
    "\n",
    "def make_circle_mask  (mask_shape, centers, radii):\n",
    "    \"\"\"\n",
    "    Creates a mask for a circle of a given radius and center.\n",
    "    \"\"\"\n",
    "    mask = np.zeros(mask_shape[:2])\n",
    "    for c, r in zip(centers, radii):\n",
    "        mask += mask_ellipse(np.ones_like(mask), c, r, r)\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To identify the repeating shape, we need to create a \"mask\" of the same shape as the objects\n",
    "# Let's crop the image to get a sense for the dimensions\n",
    "\n",
    "MIN_X = 215\n",
    "MIN_Y = 385\n",
    "MAX_X = 264\n",
    "MAX_Y = 445\n",
    "plt.imshow(rgb_img[MIN_Y:MAX_Y, MIN_X:MAX_X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GRAD_RADIUS_X = int((MAX_X - MIN_X)/2)\n",
    "GRAD_RADIUS_Y = int((MAX_Y - MIN_Y)/2)\n",
    "            \n",
    "# centers  = [[590,400], [1250,400], [880,1000]]\n",
    "# radii = [310, 310, 310]\n",
    "\n",
    "grad_centers  = [[GRAD_RADIUS_X,GRAD_RADIUS_Y]]\n",
    "grad_radii = [(GRAD_RADIUS_X, GRAD_RADIUS_Y)]\n",
    "grad_im_size = (2*grad_radii[0][1], 2*grad_radii[0][0])\n",
    "# np.array(data_dict['round']['t0']['image']).shape\n",
    "grad_template_mask = ((1-make_ellipse_masks(grad_im_size, grad_centers, grad_radii))*254).astype(np.uint8)\n",
    "plt.imshow(rgb_img[MIN_Y:MAX_Y, MIN_X:MAX_X])\n",
    "plt.imshow(grad_template_mask, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.bands.centers[170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make masks to get signal from multiple experiments with plates of the same size\n",
    "BINARY_THRESHOLD = 0.56 # the threshold for the binary mask \n",
    "BANDS = [690, 900]\n",
    "\n",
    "# Could include > 1 image\n",
    "grad_img_ls = [hsi_img]\n",
    "plate_positions = []\n",
    "\n",
    "\n",
    "# convert images to gray scale for identification\n",
    "grad_img_gray_ls = []\n",
    "band_idx_1 = np.argmin(np.abs(np.array(lib.bands.centers) - BANDS[0]))\n",
    "band_idx_2 = np.argmin(np.abs(np.array(lib.bands.centers) - BANDS[1]))\n",
    "for h_img in grad_img_ls:\n",
    "    ratio_img = h_img[:,:,band_idx_1]/h_img[:,:,band_idx_2]\n",
    "    ratio_img = (ratio_img-np.min(ratio_img)) / (np.max(ratio_img)-np.min(ratio_img))\n",
    "    grad_img_gray_ls.append((ratio_img*254).astype(np.uint8))\n",
    "\n",
    "# # Apply template matching\n",
    "matching_results = []\n",
    "matching_stats = []\n",
    "grad_mask_ls = []\n",
    "for gray in grad_img_gray_ls:\n",
    "    plt.figure()\n",
    "    plt.title(f'Gray image from band ratio {lib.bands.centers[band_idx_1]} / {lib.bands.centers[band_idx_2]}')\n",
    "    plt.imshow(gray)\n",
    "    plt.show()\n",
    "    result = cv2.matchTemplate(gray, grad_template_mask, cv2.TM_CCOEFF_NORMED)\n",
    "    plt.figure()\n",
    "    plt.title('Map of template shape matching, thresholded')\n",
    "    plt.imshow(gray, cmap='Greys')\n",
    "    plt.imshow(np.pad(result, [[GRAD_RADIUS_Y,GRAD_RADIUS_Y], [GRAD_RADIUS_X,GRAD_RADIUS_X]]), alpha=0.4)\n",
    "    plt.show()\n",
    "    # Threshold the result\n",
    "    _, result = cv2.threshold(result, BINARY_THRESHOLD, 1, cv2.THRESH_BINARY)\n",
    "    result = (np.array(result)*254).astype(np.uint8)\n",
    "    result = np.pad(result, [[GRAD_RADIUS_Y,GRAD_RADIUS_Y], [GRAD_RADIUS_X,GRAD_RADIUS_X]])\n",
    "    matching_results.append(result)\n",
    "    \n",
    "    _, _, stats, centroids = cv2.connectedComponentsWithStats(result, connectivity=8)\n",
    "\n",
    "    grad_found_centers = [c for c,s in zip(centroids[1:], stats[1:]) if s[4]>10]\n",
    "    grad_found_centers = sort_grid_list(grad_found_centers, tolerance=25)\n",
    "    plate_positions.append(grad_found_centers)\n",
    "    plt.figure()\n",
    "    plt.title('Map of template shape matching')\n",
    "    plt.imshow(gray, cmap='Greys')\n",
    "    plt.imshow(result, alpha=0.4)\n",
    "    plt.show()\n",
    "    \n",
    "    grad_masks = []\n",
    "    for c in grad_found_centers:\n",
    "        grad_masks.append(make_ellipse_masks(np.array(gray).shape, [c], [(GRAD_RADIUS_X, GRAD_RADIUS_Y)]))\n",
    "    \n",
    "    grad_mask_ls.append(grad_masks)\n",
    "    plt.figure()\n",
    "    plt.imshow(gray, cmap='Greys')\n",
    "\n",
    "    tab20 = plt.get_cmap('tab20')\n",
    "    for idx, (m,c) in enumerate(zip(grad_masks,grad_found_centers)):\n",
    "        m[m==0] = np.nan\n",
    "        m = m[:,:,np.newaxis] * np.array(tab20(idx))\n",
    "        plt.imshow(m, alpha=0.5,)\n",
    "        plt.text(x=c[0],y=c[1],s=str(idx))\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# #     for i in range(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "conc_map = pd.read_csv('data/input/087_ELOP Eden Fleshler/results/concentration_map.csv', header=None).values\n",
    "print(conc_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to aggregate the scores across a plate\n",
    "score_fxn = lambda x: np.nanmean(x) \n",
    "\n",
    "\n",
    "grad_scores_ls = []\n",
    "grad_abs_ls = []\n",
    "grad_norm_abs_ls = []\n",
    "\n",
    "\n",
    "for grad_masks, grad_scored, img in zip(grad_mask_ls, [scored_gradient], grad_img_ls):\n",
    "    single_wl_img = img[:,:,np.argmax(reference_spec)]\n",
    "    img_sum = np.sum(img, axis=2)\n",
    "    grad_scores = []\n",
    "    grad_abs = []\n",
    "    grad_norm_abs = []\n",
    "    for mask in tqdm(grad_masks):\n",
    "        grad_scores.append(score_fxn(mask*grad_scored))\n",
    "        grad_abs.append(1-score_fxn(mask*single_wl_img))\n",
    "        grad_norm_abs.append(1-score_fxn(mask*single_wl_img/img_sum))\n",
    "    grad_scores_ls.append(grad_scores)\n",
    "    grad_abs_ls.append(grad_abs)\n",
    "    grad_norm_abs_ls.append(grad_norm_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the concentration map into a single vector\n",
    "grad_concs = np.array([x for y in conc_map for x in y])\n",
    "grad_mean_classification = np.array(grad_scores_ls[0])\n",
    "grad_concs = np.array(grad_concs)[~np.isnan(grad_concs)]\n",
    "\n",
    "data_df = pd.DataFrame({'pC-HSL (nM)':np.array(grad_concs), 'Classification Score (mean)':np.array(grad_mean_classification)})\n",
    "\n",
    "print (f'{SAVEDIR}/{date_str}sensing_on_sand_hill_plot.pdf')\n",
    "plt.scatter(np.array(grad_concs), np.array(grad_mean_classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UNCOMMENT TO SAVE DATA\n",
    "savepath = f'{SAVEDIR}/{date_str}_data.csv'\n",
    "print (f'data saved to {savepath}')\n",
    "data_df.to_csv(savepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spectral",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
